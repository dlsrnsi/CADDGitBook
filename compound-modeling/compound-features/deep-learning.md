# Deep Learning

## 1. Graph Based Model

*  [Convolutional Networks on Graphsfor Learning Molecular Fingerprints \(Neural Fingerprint, 2015\)](https://arxiv.org/pdf/1509.09292.pdf)
*  [Molecular Graph Convolutions: Moving Beyond Fingerprints \(2016\)](https://link.springer.com/article/10.1007/s10822-016-9938-8)
*  [Gated Graph Sequence Neural Networks \(GG-NN, 2016\)](https://arxiv.org/pdf/1511.05493.pdf)
*  [Neural Message Passing for Quantum Chemistry \(MPNN, 2017\)](https://arxiv.org/abs/1704.01212)
*  [Message Passing Neural Networks for MolecularProperty Prediction \(D-MPNN, 2019\)](https://dspace.mit.edu/bitstream/handle/1721.1/123133/1128814048-MIT.pdf?sequence=1&isAllowed=y)
*  [Pushing the Boundaries of Molecular Representation for Drug Discovery with the Graph Attention Mechanism \(GAT, 2020\)](https://pubs.acs.org/doi/abs/10.1021/acs.jmedchem.9b00959)
*  [Self-Supervised Graph Transformer on Large-Scale Molecular Data \(GROVER, 2020\)](https://arxiv.org/abs/2007.02835)
*  [MolCLR: Molecular Contrastive Learning of Representations via Graph Neural Network \(MolCLR, 2021\)](https://arxiv.org/pdf/2102.10056.pdf)

### 1.1 Graph Motifs

*  [Motif-driven contrastive learning of graph representations \(MICRO-Graph, 2021\)](https://openreview.net/pdf?id=qcKh_Msv1GP)

## 2. NLP based Model

*  [Mol2vec: Unsupervised Machine Learning Approach with Chemical Intuition \(Mol2vec, 2018\)](https://pubs.acs.org/doi/full/10.1021/acs.jcim.7b00616)

### 2.1 Transformer based model

*  [SMILES Transformer: Pre-trained Molecular Fingerprint for Low Data Drug Discovery \(SMILES Transformer, 2019\)](https://arxiv.org/abs/1911.04738)
*  [SMILES-BERT: Large Scale Unsupervised Pre-Training for Molecular Property Prediction \(SMILES-BERT, 2019\)](https://dl.acm.org/doi/10.1145/3307339.3342186)
*  [Molecule Attention Transformer \(MAT, 2020\)](https://arxiv.org/abs/2002.08264)
*  [ChemBERTa: Large-Scale Self-Supervised Pretraining for Molecular Property Prediction \(ChemBERTa, 2020\)](https://arxiv.org/abs/2010.09885)



